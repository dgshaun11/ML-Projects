{"cells":[{"source":"![Credit card being held in hand](credit_card.jpg)\n\nCommercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n\n### The Data\n\nThe data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value.","metadata":{},"id":"35aebf2e-0635-4fef-bc9a-877b6a20fb13","cell_type":"markdown"},{"source":"","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1742258269713,"lastExecutedByKernel":"7d641842-22db-47cd-b468-b158807066c5","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"180922f1-5bea-40df-b148-b6a1be99fbef","outputs":[],"execution_count":6},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()\n\ncc_apps.replace(\"?\", np.nan, inplace=True)\nfor col in cc_apps.select_dtypes(include=['number']).columns:\n    cc_apps[col].fillna(cc_apps[col].mean(), inplace=True)\nfor col in cc_apps.select_dtypes(include=['object']).columns:\n    cc_apps[col].fillna(cc_apps[col].mode()[0], inplace=True)\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor col in cc_apps.select_dtypes(include=['object']).columns:\n    cc_apps[col] = le.fit_transform(cc_apps[col])\n\nX = cc_apps.iloc[:, :-1]\ny = cc_apps.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\nfrom sklearn.metrics import accuracy_score, classification_report\ny_pred = model.predict(X_test)\nprint(\"accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"classification:\", classification_report(y_test, y_pred))\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],\n    'solver': ['liblinear', 'lbfgs']\n}\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\nprint(\"best parameters:\", grid_search.best_params_)\nbest_model = grid_search.best_estimator_","metadata":{"executionCancelledAt":null,"executionTime":212,"lastExecutedAt":1742258269925,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()\n\ncc_apps.replace(\"?\", np.nan, inplace=True)\nfor col in cc_apps.select_dtypes(include=['number']).columns:\n    cc_apps[col].fillna(cc_apps[col].mean(), inplace=True)\nfor col in cc_apps.select_dtypes(include=['object']).columns:\n    cc_apps[col].fillna(cc_apps[col].mode()[0], inplace=True)\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor col in cc_apps.select_dtypes(include=['object']).columns:\n    cc_apps[col] = le.fit_transform(cc_apps[col])\n\nX = cc_apps.iloc[:, :-1]\ny = cc_apps.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\nfrom sklearn.metrics import accuracy_score, classification_report\ny_pred = model.predict(X_test)\nprint(\"accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"classification:\", classification_report(y_test, y_pred))\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],\n    'solver': ['liblinear', 'lbfgs']\n}\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\nprint(\"best parameters:\", grid_search.best_params_)\nbest_model = grid_search.best_estimator_","outputsMetadata":{"0":{"height":248,"type":"stream"}},"lastExecutedByKernel":"7d641842-22db-47cd-b468-b158807066c5","visualizeDataframe":false,"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"}},"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","cell_type":"code","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"accuracy: 0.8333333333333334\nclassification:               precision    recall  f1-score   support\n\n           0       0.83      0.84      0.84        70\n           1       0.84      0.82      0.83        68\n\n    accuracy                           0.83       138\n   macro avg       0.83      0.83      0.83       138\nweighted avg       0.83      0.83      0.83       138\n\nbest parameters: {'C': 0.1, 'solver': 'liblinear'}\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}